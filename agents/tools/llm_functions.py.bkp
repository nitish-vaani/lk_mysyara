import asyncio
import json
import logging
from typing import Annotated
from livekit import api, rtc
from livekit.agents import Agent, function_tool, RunContext, JobContext
from livekit.plugins import openai
import aiohttp
import os
from dotenv import load_dotenv
import subprocess
from agent_assist.identify_free_agent import *
from time import perf_counter

load_dotenv(dotenv_path=".env.local")
event_id = os.getenv("EVENT_TYPE_ID")
base_url = os.getenv("base_url")
url_ = os.getenv("base_url")
lk_api_key = os.getenv("LIVEKIT_API_KEY")
lk_url = os.getenv("LIVEKIT_URL")
lk_api_secret = os.getenv("LIVEKIT_API_SECRET")
lk_sip_outbound_trunk_id = os.getenv("SIP_OUTBOUND_TRUNK_ID")

logger = logging.getLogger("outbound-caller")

class SimplePromptCache:
    """Simple prompt caching for GPT-4o optimization"""
    
    def __init__(self, system_prompt: str):
        self.system_prompt = system_prompt
        self.cache_warmed = False
        
        # Create GPT-4o LLM with minimal parameters
        self.llm = openai.LLM(
            model="gpt-4o",
            temperature=0.7,
        )
        
        logger.info(f"üìù Prompt cache initialized with {len(system_prompt)} character prompt")
        
        # Start cache warming
        asyncio.create_task(self._warm_cache())
    
    async def _warm_cache(self):
        """Warm up the prompt cache"""
        try:
            logger.info("üöÄ Warming GPT-4o cache with system prompt...")
            start_time = perf_counter()
            
            # Create a simple chat context for warming
            from livekit.agents import llm
            
            chat_ctx = llm.ChatContext()
            chat_ctx.messages = [
                llm.ChatMessage(role="system", content=[self.system_prompt]),
                llm.ChatMessage(role="user", content=["Hello, I'm ready to start."])
            ]
            
            # Make a quick call to establish cache
            stream = self.llm.chat(chat_ctx=chat_ctx) 
            
            # Consume the response
            response_text = ""
            async for chunk in stream:
                if hasattr(chunk, 'content') and chunk.content:
                    response_text += chunk.content
            
            elapsed = perf_counter() - start_time
            logger.info(f"‚úÖ Cache warmed in {elapsed:.3f}s")
            logger.info(f"üìä Test response: '{response_text[:50]}...'")
            self.cache_warmed = True
            
        except Exception as e:
            logger.error(f"‚ùå Cache warming failed: {e}")
            # Mark as warmed anyway to avoid blocking
            self.cache_warmed = True

class CallAgent(Agent):
    """CallAgent with simple prompt caching - Step 1 Fix"""

    def __init__(self, instructions: str, ctx: JobContext):
        super().__init__(instructions=instructions)
        self.ctx = ctx
        
        # Create cache manager  
        self.cache_manager = SimplePromptCache(instructions)
        
        logger.info("üîß CallAgent initialized with simple prompt caching")

    # ALL YOUR EXISTING FUNCTION TOOLS REMAIN EXACTLY THE SAME
    @function_tool()
    async def end_call(self, context: RunContext):
        """Called when the user wants to end the call"""
        logger.info(f"Ending the call for {context.participant.identity}")
        await context.room.disconnect()

    @function_tool()
    async def detected_answering_machine(self, context: RunContext):
        """Called when the call reaches voicemail. Use this tool AFTER you hear the voicemail greeting"""
        logger.info(f"Detected answering machine for {context.participant.identity}")
        await context.room.disconnect()

    @function_tool()
    async def customer_exists(
        self,
        context: RunContext,
        customer_id: Annotated[str, "The customer ID"]
    ):
        """Checks if a customer exists in the database."""
        logger.info(f"Checking existence of customer ID: {customer_id}")
        url = f"{base_url}/customer_exists/"
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(url, json={"customer_id": customer_id}) as response:
                    logger.info(f"Response from API: {response.status}")
                    if response.status == 200:
                        data = await response.json()
                        return data
                    else:
                        logger.error(f"Error from API: {response.status}")
                        return {"error": "Failed to fetch customer details."}
            except Exception as e:
                logger.error(f"Exception in customer_exists: {e}")
                return {"error": "Internal error occurred."}

    @function_tool()
    async def transfer_to_human_agent(self):
        """
        Transfers the call to a human agent by calling their phone number and connecting them to the same room.
        Use this when the customer needs to speak to a human agent.
        """
        logger.info(f"Transferring to human agent in room {self.room.name}")
        room_name = self.room.name
        CMD = [
                "lk", "room", "participants", "list", room_name,
                "--api-key", lk_api_key,
                "--api-secret", lk_api_secret,
                "--url", lk_url,
            ]

        cmd_result = subprocess.run(CMD, check=True, capture_output=True, text=True)
        participants = cmd_result.stdout.splitlines()
        agent_participant = [p for p in participants if p.strip().startswith("agent-")]
        correct_identity = agent_participant[0].split()[0] if agent_participant else None
        logger.info(f"Participants in room {self.room.name}: {participants}")

        #Get the free agent.
        agent_phone = free_human_agent()

        try:
            # Create a SIP participant for the human agent
            async with api.LiveKitAPI(
                url=lk_url,
                api_key=lk_api_key,
                api_secret=lk_api_secret,
            ) as lkapi:
                # Add the human agent to the room via SIP
                await lkapi.sip.create_sip_participant(
                    api.CreateSIPParticipantRequest(
                        room_name=self.room.name,
                        sip_trunk_id=lk_sip_outbound_trunk_id,
                        sip_call_to=agent_phone,
                        participant_identity="human-agent",
                    )
                )
                logger.info(f"Created SIP participant for human agent with phone {agent_phone}")
                
                # Wait for human agent to connect
                await asyncio.sleep(3)
                
                # Inform the customer about the transfer
                transfer_message = "I'm transferring you to a human agent who can better assist you. Please hold while I connect you."
                
                # After transfer message is delivered, set AI agent to inactive 
                async def after_transfer():
                    await asyncio.sleep(5)
                    
                    await lkapi.room.update_participant(
                        api.UpdateParticipantRequest(
                            room=self.room.name,
                            identity=self.room.local_participant.identity,
                            metadata=json.dumps({"status": "inactive"}),
                        )
                    )
                    logger.info("AI agent marked as inactive")
                
                # Start the after-transfer process
                asyncio.create_task(after_transfer())
                
                return transfer_message
                
        except Exception as e:
            logger.error(f"Error transferring to human agent: {e}")
            return "I apologize, but I'm unable to transfer you to a human agent at this time. Let's continue our conversation."

    @function_tool()
    async def get_room_details(self, context: RunContext):
        """Returns details about the current room."""
        room = self.ctx.room
        return room.name